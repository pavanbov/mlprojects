{"cells":[{"metadata":{},"cell_type":"markdown","source":"#### Handwritten Digit Recognization is one of the oldest problem of Machine Learning and is used to baseline performance of new algorithm.\n\n#### I will share my way of addressing this challenge starting from applying Classification algorithms, PCA, Neural Network and ultimately CNN.\n\n#### There is ample scope to improve this Notebook but I am sure the small footsteps outlined here will be helpful to solidify our learning."},{"metadata":{},"cell_type":"markdown","source":"#### Import the basic libraries."},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom pandas import DataFrame\n%matplotlib inline","execution_count":1,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Load the train data."},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"train_data = pd.read_csv(\"../input/digit-recognizer/train.csv\")","execution_count":2,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Explore train data."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.head()","execution_count":3,"outputs":[{"output_type":"execute_result","execution_count":3,"data":{"text/plain":"   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n0      1       0       0       0       0       0       0       0       0   \n1      0       0       0       0       0       0       0       0       0   \n2      1       0       0       0       0       0       0       0       0   \n3      4       0       0       0       0       0       0       0       0   \n4      0       0       0       0       0       0       0       0       0   \n\n   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n0       0  ...         0         0         0         0         0         0   \n1       0  ...         0         0         0         0         0         0   \n2       0  ...         0         0         0         0         0         0   \n3       0  ...         0         0         0         0         0         0   \n4       0  ...         0         0         0         0         0         0   \n\n   pixel780  pixel781  pixel782  pixel783  \n0         0         0         0         0  \n1         0         0         0         0  \n2         0         0         0         0  \n3         0         0         0         0  \n4         0         0         0         0  \n\n[5 rows x 785 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>label</th>\n      <th>pixel0</th>\n      <th>pixel1</th>\n      <th>pixel2</th>\n      <th>pixel3</th>\n      <th>pixel4</th>\n      <th>pixel5</th>\n      <th>pixel6</th>\n      <th>pixel7</th>\n      <th>pixel8</th>\n      <th>...</th>\n      <th>pixel774</th>\n      <th>pixel775</th>\n      <th>pixel776</th>\n      <th>pixel777</th>\n      <th>pixel778</th>\n      <th>pixel779</th>\n      <th>pixel780</th>\n      <th>pixel781</th>\n      <th>pixel782</th>\n      <th>pixel783</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 785 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### The 'label' is the target column and it says whether the values of pixel0 to pixel784 make it to any digit from 0 to 9.\n\n#### Each pixel has value in the range of 0 to 255."},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data.shape","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"(42000, 785)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### Separate out predictor variables i.e pixel values and label."},{"metadata":{"trusted":true},"cell_type":"code","source":"model_train_data_unscaled = train_data.drop(['label'], axis=1)\nmodel_train_label = train_data['label']","execution_count":5,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's visualize one row of the train dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.imshow(np.array(model_train_data_unscaled.loc[10]).reshape(28, 28), cmap='Greys')\nprint(model_train_label[10])","execution_count":6,"outputs":[{"output_type":"stream","text":"8\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{},"cell_type":"markdown","source":"#### There is no missing value and there is very little scope of feature engineering; so we will only do scaling of pixel values to bring them within 0 and 1."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import MinMaxScaler\n\nstd_scaler = MinMaxScaler()\nmodel_train_data = std_scaler.fit_transform(model_train_data_unscaled.astype(np.float64))","execution_count":7,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### We will create a standard function so that we can have similar metrics displayed for different algorithms."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.model_selection import cross_val_score, cross_val_predict, GridSearchCV\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, roc_curve, roc_auc_score, precision_recall_curve\n\ndef model_def(model, model_name, m_train_data, m_train_label):\n    model.fit(m_train_data, m_train_label)\n    s = \"predict_\"\n    p = s + model_name\n    p = model.predict(m_train_data)\n    cm = confusion_matrix(m_train_label, p)\n    precision = np.diag(cm)/np.sum(cm, axis=0)\n    recall    = np.diag(cm)/np.sum(cm, axis=1)\n    F1 = 2 * np.mean(precision) * np.mean(recall)/(np.mean(precision) + np.mean(recall))\n    cv_score = cross_val_score(model, m_train_data, m_train_label, cv=3, scoring='accuracy')\n    print(\"Precision Is      :\", np.mean(precision))\n    print(\"Recall Is         :\", np.mean(recall))\n    print(\"F1 Score IS       :\", F1)\n    print(\"Mean CV Score     :\", cv_score.mean())\n    print(\"Std Dev CV Score  :\", cv_score.std())","execution_count":8,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Let's start applying different algorithm on the train dataset.\n\n#### Softmax Regression."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.linear_model import LogisticRegression\n\nsoftmax = LogisticRegression(max_iter=1000, solver='lbfgs', multi_class='multinomial', C=0.05)\nmodel_def(softmax, \"softmax\", model_train_data, model_train_label)","execution_count":9,"outputs":[{"output_type":"stream","text":"Precision Is      : 0.9285167036162614\nRecall Is         : 0.9283923949551989\nF1 Score IS       : 0.9284545451248793\nMean CV Score     : 0.917404761904762\nStd Dev CV Score  : 0.0005899767473030273\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### Now we will apply PCA and which is one of the main dimensionality reduction technique. PCA stands for Principal Component Analysis and here the columns across which the data has maximum variability are retained; so we can drop few columns without losing significant amount of insights."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.decomposition import PCA\n\npca = PCA(n_components = 200)\nmodel_train_data2D = pca.fit_transform(model_train_data)\nprint(\"Explained Variance Ratio:\", np.sum(pca.explained_variance_ratio_))","execution_count":10,"outputs":[{"output_type":"stream","text":"Explained Variance Ratio: 0.9661605279836099\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### So you can see if we use only 200 columns out of 784 columns we are able to explain 96.61% variability of the data.\n\n#### We will use this updated dataset on Polynomial Kernel Classification."},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.svm import SVC\n\npoly6 = SVC(C=2, kernel='poly', degree=3, gamma='auto', random_state=42)\nmodel_def(poly6, \"poly6\", model_train_data2D, model_train_label)","execution_count":11,"outputs":[{"output_type":"stream","text":"Precision Is      : 0.9468095193993629\nRecall Is         : 0.9456733197372247\nF1 Score IS       : 0.9462410784952744\nMean CV Score     : 0.9238333333333334\nStd Dev CV Score  : 0.0029331168751303652\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### We can see a slight improvement in model performance.\n\n#### Now we will apply ANN to solve the challenge. Since we want to use the standard function to display model metrics like CV score we need to build an wrapper."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier","execution_count":12,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"def build_classifier():\n    classifier = Sequential([Dense(128, kernel_initializer='random_uniform', activation='relu', input_shape=(200,)),\n                             Dropout(rate=0.2),\n                             Dense(128, kernel_initializer='random_uniform', activation='relu'),\n                             Dropout(rate=0.2),\n                             Dense(10, kernel_initializer='random_uniform', activation='softmax')])\n    classifier.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    \n    return classifier\n\nANN_classifier = KerasClassifier(build_fn=build_classifier, batch_size=100, epochs=20)\nANN_classifier.fit(model_train_data2D, model_train_label)","execution_count":13,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n42000/42000 [==============================] - 2s 54us/step - loss: 0.5489 - accuracy: 0.8589\nEpoch 2/20\n42000/42000 [==============================] - 1s 29us/step - loss: 0.1958 - accuracy: 0.9405\nEpoch 3/20\n42000/42000 [==============================] - 1s 29us/step - loss: 0.1458 - accuracy: 0.9565\nEpoch 4/20\n42000/42000 [==============================] - 1s 30us/step - loss: 0.1168 - accuracy: 0.9640\nEpoch 5/20\n42000/42000 [==============================] - 1s 30us/step - loss: 0.0990 - accuracy: 0.9691\nEpoch 6/20\n42000/42000 [==============================] - 1s 32us/step - loss: 0.0833 - accuracy: 0.9744\nEpoch 7/20\n42000/42000 [==============================] - 1s 30us/step - loss: 0.0732 - accuracy: 0.9761\nEpoch 8/20\n42000/42000 [==============================] - 1s 30us/step - loss: 0.0674 - accuracy: 0.9787\nEpoch 9/20\n42000/42000 [==============================] - 1s 31us/step - loss: 0.0611 - accuracy: 0.9813\nEpoch 10/20\n42000/42000 [==============================] - 1s 31us/step - loss: 0.0535 - accuracy: 0.9823\nEpoch 11/20\n42000/42000 [==============================] - 1s 31us/step - loss: 0.0487 - accuracy: 0.9833\nEpoch 12/20\n42000/42000 [==============================] - 1s 29us/step - loss: 0.0468 - accuracy: 0.9845\nEpoch 13/20\n42000/42000 [==============================] - 1s 30us/step - loss: 0.0423 - accuracy: 0.9863\nEpoch 14/20\n42000/42000 [==============================] - 1s 35us/step - loss: 0.0374 - accuracy: 0.9875\nEpoch 15/20\n42000/42000 [==============================] - 1s 34us/step - loss: 0.0362 - accuracy: 0.9878\nEpoch 16/20\n42000/42000 [==============================] - 1s 30us/step - loss: 0.0348 - accuracy: 0.9880\nEpoch 17/20\n42000/42000 [==============================] - 1s 31us/step - loss: 0.0336 - accuracy: 0.9890\nEpoch 18/20\n42000/42000 [==============================] - 1s 30us/step - loss: 0.0316 - accuracy: 0.9895\nEpoch 19/20\n42000/42000 [==============================] - 1s 30us/step - loss: 0.0288 - accuracy: 0.9905\nEpoch 20/20\n42000/42000 [==============================] - 1s 29us/step - loss: 0.0288 - accuracy: 0.9905\n","name":"stdout"},{"output_type":"execute_result","execution_count":13,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7f053c0a2c90>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"cv_score = cross_val_score(ANN_classifier, model_train_data2D, model_train_label, cv=5, scoring='accuracy')\nprint(\"Mean CV Score Is:\", cv_score.mean())","execution_count":14,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n33600/33600 [==============================] - 1s 36us/step - loss: 0.6172 - accuracy: 0.8433\nEpoch 2/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.2121 - accuracy: 0.9354\nEpoch 3/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.1611 - accuracy: 0.9509\nEpoch 4/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.1263 - accuracy: 0.9612\nEpoch 5/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.1044 - accuracy: 0.9676\nEpoch 6/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0909 - accuracy: 0.9714\nEpoch 7/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.0775 - accuracy: 0.9752\nEpoch 8/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.0689 - accuracy: 0.9786\nEpoch 9/20\n33600/33600 [==============================] - 1s 33us/step - loss: 0.0597 - accuracy: 0.9810\nEpoch 10/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0545 - accuracy: 0.9817\nEpoch 11/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.0513 - accuracy: 0.9835\nEpoch 12/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.0458 - accuracy: 0.9851\nEpoch 13/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.0426 - accuracy: 0.9861\nEpoch 14/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.0388 - accuracy: 0.9872\nEpoch 15/20\n33600/33600 [==============================] - 1s 41us/step - loss: 0.0377 - accuracy: 0.9880\nEpoch 16/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0331 - accuracy: 0.9887\nEpoch 17/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0331 - accuracy: 0.9880\nEpoch 18/20\n33600/33600 [==============================] - 1s 36us/step - loss: 0.0304 - accuracy: 0.9905\nEpoch 19/20\n33600/33600 [==============================] - 1s 42us/step - loss: 0.0300 - accuracy: 0.9904\nEpoch 20/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0288 - accuracy: 0.9901\nEpoch 1/20\n33600/33600 [==============================] - 1s 37us/step - loss: 0.6088 - accuracy: 0.8427\nEpoch 2/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.2185 - accuracy: 0.9338\nEpoch 3/20\n33600/33600 [==============================] - 1s 34us/step - loss: 0.1639 - accuracy: 0.9510\nEpoch 4/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.1307 - accuracy: 0.9601\nEpoch 5/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.1042 - accuracy: 0.9674\nEpoch 6/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0935 - accuracy: 0.9714\nEpoch 7/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0828 - accuracy: 0.9741\nEpoch 8/20\n33600/33600 [==============================] - 1s 33us/step - loss: 0.0722 - accuracy: 0.9765\nEpoch 9/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0642 - accuracy: 0.9792\nEpoch 10/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0572 - accuracy: 0.9816\nEpoch 11/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0516 - accuracy: 0.9832\nEpoch 12/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0486 - accuracy: 0.9842\nEpoch 13/20\n33600/33600 [==============================] - 1s 32us/step - loss: 0.0428 - accuracy: 0.9856\nEpoch 14/20\n33600/33600 [==============================] - 1s 32us/step - loss: 0.0400 - accuracy: 0.9865\nEpoch 15/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0377 - accuracy: 0.9872\nEpoch 16/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0382 - accuracy: 0.9866\nEpoch 17/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0343 - accuracy: 0.9889\nEpoch 18/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0313 - accuracy: 0.9893\nEpoch 19/20\n33600/33600 [==============================] - 1s 34us/step - loss: 0.0309 - accuracy: 0.9897\nEpoch 20/20\n33600/33600 [==============================] - 1s 32us/step - loss: 0.0292 - accuracy: 0.9896\nEpoch 1/20\n33600/33600 [==============================] - 1s 36us/step - loss: 0.6102 - accuracy: 0.8457\nEpoch 2/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.2092 - accuracy: 0.9368\nEpoch 3/20\n33600/33600 [==============================] - 1s 32us/step - loss: 0.1566 - accuracy: 0.9526\nEpoch 4/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.1247 - accuracy: 0.9626\nEpoch 5/20\n33600/33600 [==============================] - 1s 32us/step - loss: 0.1032 - accuracy: 0.9680\nEpoch 6/20\n33600/33600 [==============================] - 1s 35us/step - loss: 0.0911 - accuracy: 0.9712\nEpoch 7/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0764 - accuracy: 0.9761\nEpoch 8/20\n33600/33600 [==============================] - 1s 34us/step - loss: 0.0691 - accuracy: 0.9783\nEpoch 9/20\n33600/33600 [==============================] - 1s 32us/step - loss: 0.0608 - accuracy: 0.9803\nEpoch 10/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0519 - accuracy: 0.9829\nEpoch 11/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0489 - accuracy: 0.9842\nEpoch 12/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.0447 - accuracy: 0.9849\nEpoch 13/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.0423 - accuracy: 0.9860\nEpoch 14/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.0394 - accuracy: 0.9870\nEpoch 15/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.0363 - accuracy: 0.9881\nEpoch 16/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0349 - accuracy: 0.9883\nEpoch 17/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0323 - accuracy: 0.9891\nEpoch 18/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.0302 - accuracy: 0.9892\nEpoch 19/20\n33600/33600 [==============================] - 1s 34us/step - loss: 0.0263 - accuracy: 0.9914\nEpoch 20/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0276 - accuracy: 0.9907\nEpoch 1/20\n33600/33600 [==============================] - 1s 35us/step - loss: 0.6163 - accuracy: 0.8469\nEpoch 2/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.2161 - accuracy: 0.9338\nEpoch 3/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.1612 - accuracy: 0.9517\nEpoch 4/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.1283 - accuracy: 0.9600\nEpoch 5/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.1072 - accuracy: 0.9661\nEpoch 6/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0889 - accuracy: 0.9724\nEpoch 7/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0771 - accuracy: 0.9762\nEpoch 8/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0695 - accuracy: 0.9779\nEpoch 9/20\n33600/33600 [==============================] - 1s 43us/step - loss: 0.0603 - accuracy: 0.9806\nEpoch 10/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0514 - accuracy: 0.9836\nEpoch 11/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0493 - accuracy: 0.9840\nEpoch 12/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0439 - accuracy: 0.9857\nEpoch 13/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0417 - accuracy: 0.9862\nEpoch 14/20\n33600/33600 [==============================] - 1s 38us/step - loss: 0.0388 - accuracy: 0.9871\nEpoch 15/20\n33600/33600 [==============================] - 1s 36us/step - loss: 0.0349 - accuracy: 0.9881\nEpoch 16/20\n33600/33600 [==============================] - 1s 32us/step - loss: 0.0341 - accuracy: 0.9889\nEpoch 17/20\n33600/33600 [==============================] - 1s 32us/step - loss: 0.0327 - accuracy: 0.9886\nEpoch 18/20\n","name":"stdout"},{"output_type":"stream","text":"33600/33600 [==============================] - 1s 37us/step - loss: 0.0293 - accuracy: 0.9896\nEpoch 19/20\n33600/33600 [==============================] - 1s 32us/step - loss: 0.0301 - accuracy: 0.9901\nEpoch 20/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0275 - accuracy: 0.9906\nEpoch 1/20\n33600/33600 [==============================] - 1s 36us/step - loss: 0.6269 - accuracy: 0.8282\nEpoch 2/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.2254 - accuracy: 0.9324\nEpoch 3/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.1628 - accuracy: 0.9517\nEpoch 4/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.1344 - accuracy: 0.9600\nEpoch 5/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.1100 - accuracy: 0.9662\nEpoch 6/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0942 - accuracy: 0.9712\nEpoch 7/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0791 - accuracy: 0.9757\nEpoch 8/20\n33600/33600 [==============================] - 1s 34us/step - loss: 0.0731 - accuracy: 0.9772\nEpoch 9/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0643 - accuracy: 0.9799\nEpoch 10/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.0553 - accuracy: 0.9813\nEpoch 11/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.0514 - accuracy: 0.9829\nEpoch 12/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0473 - accuracy: 0.9845\nEpoch 13/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0427 - accuracy: 0.9857\nEpoch 14/20\n33600/33600 [==============================] - 1s 30us/step - loss: 0.0385 - accuracy: 0.9867\nEpoch 15/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0370 - accuracy: 0.9877\nEpoch 16/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0348 - accuracy: 0.9889\nEpoch 17/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0325 - accuracy: 0.9892\nEpoch 18/20\n33600/33600 [==============================] - 1s 34us/step - loss: 0.0337 - accuracy: 0.9885\nEpoch 19/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0293 - accuracy: 0.9901\nEpoch 20/20\n33600/33600 [==============================] - 1s 31us/step - loss: 0.0279 - accuracy: 0.9905\nMean CV Score Is: 0.9734285714285715\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Mean CV Score Is:\", cv_score.mean())","execution_count":15,"outputs":[{"output_type":"stream","text":"Mean CV Score Is: 0.9734285714285715\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### So we can see a significant improvement in accuracy using an ANN to classify.\n\n#### Now we will use test data to predict."},{"metadata":{"trusted":true},"cell_type":"code","source":"test_data = pd.read_csv(\"../input/digit-recognizer/test.csv\")\n\nmodel_test_data = std_scaler.transform(test_data.astype(np.float64))\nmodel_test_data2D = pca.transform(model_test_data)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_test_poly6 = poly6.predict(model_test_data2D)","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_test_softmax = softmax.predict(model_test_data)\npredict_test_ANN = ANN_classifier.predict(model_test_data2D)\n\nId = DataFrame(np.arange(1,28001))\nId.columns = ['ImageId']\n\nprediction = DataFrame(predict_test_poly6)\nprediction.columns = ['Label']\n\nresult = pd.concat([Id, prediction], axis=1)\nresult.to_csv(\"Submission_Poly.csv\", index=False)\n\nId = DataFrame(np.arange(1,28001))\nId.columns = ['ImageId']\n\nprediction = DataFrame(predict_test_softmax)\nprediction.columns = ['Label']\n\nresult = pd.concat([Id, prediction], axis=1)\nresult.to_csv(\"Submission_Softmax.csv\", index=False)\n\nId = DataFrame(np.arange(1,28001))\nId.columns = ['ImageId']\n\nprediction = DataFrame(predict_test_ANN)\nprediction.columns = ['Label']\n\nresult = pd.concat([Id, prediction], axis=1)\nresult.to_csv(\"Submission_ANN.csv\", index=False)","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Now we will apply Convolutional Neural Network(CNN) techniques on the original data."},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Flatten\nfrom keras.layers import Dense, Dropout","execution_count":19,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### Reshaping the data to the format Convolution layer expects.\n\n#### Input shape - 4D tensor with shape: (batch_size, channels, rows, cols) if data_format='channels_first' or 4D tensor with shape: (batch_size, rows, cols, channels) if data_format='channels_last'."},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = np.array(model_train_data_unscaled).reshape(42000, 28, 28, 1)\ny_train = model_train_label\nX_test = np.array(test_data).reshape(28000, 28, 28, 1)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"CNN_model = Sequential([Convolution2D(filters=32, kernel_size=(3, 3), strides=(1, 1), input_shape=(28,28,1),\n                            padding='valid', activation='relu'),\n                         MaxPooling2D(pool_size=(2, 2)),\n                         Convolution2D(filters=32, kernel_size=(3, 3), strides=(1, 1),\n                            padding='valid', activation='relu'),\n                         MaxPooling2D(pool_size=(2, 2)),\n                         Flatten(),\n                         Dense(128, kernel_initializer='random_uniform', activation='relu'),\n                         Dropout(rate=0.2),\n                         Dense(128, kernel_initializer='random_uniform', activation='relu'),\n                         Dropout(rate=0.2),\n                         Dense(10, kernel_initializer='random_uniform', activation='softmax')])\n\nCNN_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n\nCNN_model.fit(X_train, y_train, batch_size=100, epochs=20)","execution_count":21,"outputs":[{"output_type":"stream","text":"Epoch 1/20\n42000/42000 [==============================] - 5s 126us/step - loss: 0.2263 - accuracy: 0.9293\nEpoch 2/20\n42000/42000 [==============================] - 2s 58us/step - loss: 0.0720 - accuracy: 0.9790\nEpoch 3/20\n42000/42000 [==============================] - 2s 53us/step - loss: 0.0514 - accuracy: 0.9850\nEpoch 4/20\n42000/42000 [==============================] - 2s 52us/step - loss: 0.0443 - accuracy: 0.9873\nEpoch 5/20\n42000/42000 [==============================] - 2s 56us/step - loss: 0.0375 - accuracy: 0.9885\nEpoch 6/20\n42000/42000 [==============================] - 3s 62us/step - loss: 0.0338 - accuracy: 0.9905\nEpoch 7/20\n42000/42000 [==============================] - 2s 59us/step - loss: 0.0298 - accuracy: 0.9908\nEpoch 8/20\n42000/42000 [==============================] - 2s 53us/step - loss: 0.0280 - accuracy: 0.9911\nEpoch 9/20\n42000/42000 [==============================] - 2s 58us/step - loss: 0.0256 - accuracy: 0.9922\nEpoch 10/20\n42000/42000 [==============================] - 2s 55us/step - loss: 0.0242 - accuracy: 0.9927\nEpoch 11/20\n42000/42000 [==============================] - 2s 55us/step - loss: 0.0240 - accuracy: 0.9927\nEpoch 12/20\n42000/42000 [==============================] - 2s 54us/step - loss: 0.0198 - accuracy: 0.9941\nEpoch 13/20\n42000/42000 [==============================] - 2s 53us/step - loss: 0.0154 - accuracy: 0.9953\nEpoch 14/20\n42000/42000 [==============================] - 2s 56us/step - loss: 0.0204 - accuracy: 0.9940\nEpoch 15/20\n42000/42000 [==============================] - 2s 58us/step - loss: 0.0206 - accuracy: 0.9937\nEpoch 16/20\n42000/42000 [==============================] - 2s 53us/step - loss: 0.0149 - accuracy: 0.9955\nEpoch 17/20\n42000/42000 [==============================] - 2s 53us/step - loss: 0.0170 - accuracy: 0.9948\nEpoch 18/20\n42000/42000 [==============================] - 2s 53us/step - loss: 0.0151 - accuracy: 0.9957\nEpoch 19/20\n42000/42000 [==============================] - 2s 57us/step - loss: 0.0152 - accuracy: 0.9955\nEpoch 20/20\n42000/42000 [==============================] - 2s 53us/step - loss: 0.0152 - accuracy: 0.9955\n","name":"stdout"},{"output_type":"execute_result","execution_count":21,"data":{"text/plain":"<keras.callbacks.callbacks.History at 0x7f0450322e90>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = CNN_model.predict(X_test)\ny_test.shape","execution_count":22,"outputs":[{"output_type":"execute_result","execution_count":22,"data":{"text/plain":"(28000, 10)"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"predict_test_CNN = np.argmax(y_test, axis=1)\nplt.imshow(np.array(test_data.loc[0]).reshape(28, 28), cmap='Greys')\nprint(predict_test_CNN[0])","execution_count":23,"outputs":[{"output_type":"stream","text":"2\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"Id = DataFrame(np.arange(1,28001))\nId.columns = ['ImageId']\n\nprediction = DataFrame(predict_test_CNN)\nprediction.columns = ['Label']\n\nresult = pd.concat([Id, prediction], axis=1)\nresult.to_csv(\"Submission_CNN.csv\", index=False)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}